{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '/home/ray/default')\n",
    "\n",
    "import os\n",
    "from util.utils import (\n",
    "    generate_output_path,\n",
    "    prompt_for_hugging_face_token\n",
    ")\n",
    "import ray\n",
    "import os\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/datasets/DBQ/Burberry.Product.prices.United.States?row=0\n",
    "HF_DATA = \"DBQ/Burberry.Product.prices.United.States\"\n",
    "\n",
    "BASE_PATH = 's3://anyscale-customer-dataplane-data-production-us-east-2/artifact_storage/org_6687q89lgh27q3z41zesm2fsq6/cld_j25ipm5kli358v41pn9c96gjg3/BurberryData:john_:kpbdm'\n",
    "IMG_PATH = BASE_PATH + \"/images\"\n",
    "DATA_PATH = BASE_PATH + \"/data\"\n",
    "CAPTION_PATH = BASE_PATH + \"/captions/2\"\n",
    "\n",
    "IMG_PATH_TEST = \"/home/ray/default/data/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_MODEL = \"google/paligemma-3b-mix-224\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Config\n",
    "There are two modes `test` and `prod`. Test will only operate on a small subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, IntEnum\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "class RunMode(str, Enum):\n",
    "    test = 'test'\n",
    "    prod = 'prod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = RunMode.prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 69)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(np.zeros((32,69,69)).shape[0]):\n",
    "    print(np.zeros((32,69,69))[i].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ray/default/notebooks/Create-Captions.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-session-33eser3czbha2i3jm7g2t5am82.i.anyscaleuserdata.com/home/ray/default/notebooks/Create-Captions.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m LIMIT \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39mif\u001b[39;00m mode\u001b[39m==\u001b[39mRunMode\u001b[39m.\u001b[39mtest \u001b[39melse\u001b[39;00m \u001b[39m1000\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://vscode-session-33eser3czbha2i3jm7g2t5am82.i.anyscaleuserdata.com/home/ray/default/notebooks/Create-Captions.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m img_data \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mread_images(IMG_PATH, include_paths\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, override_num_blocks\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\u001b[39m.\u001b[39mlimit(LIMIT)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/anyscale/data/api/read_api.py:601\u001b[0m, in \u001b[0;36mread_images\u001b[0;34m(paths, filesystem, parallelism, meta_provider, ray_remote_args, arrow_open_file_args, partition_filter, partitioning, size, mode, include_paths, ignore_missing_paths, shuffle, file_extensions, concurrency, override_num_blocks)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[39mif\u001b[39;00m meta_provider \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    599\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(META_PROVIDER_WARNING)\n\u001b[0;32m--> 601\u001b[0m     \u001b[39mreturn\u001b[39;00m read_images_fallback(\n\u001b[1;32m    602\u001b[0m         paths,\n\u001b[1;32m    603\u001b[0m         filesystem\u001b[39m=\u001b[39;49mfilesystem,\n\u001b[1;32m    604\u001b[0m         parallelism\u001b[39m=\u001b[39;49mparallelism,\n\u001b[1;32m    605\u001b[0m         meta_provider\u001b[39m=\u001b[39;49mmeta_provider,\n\u001b[1;32m    606\u001b[0m         ray_remote_args\u001b[39m=\u001b[39;49mray_remote_args,\n\u001b[1;32m    607\u001b[0m         arrow_open_file_args\u001b[39m=\u001b[39;49marrow_open_file_args,\n\u001b[1;32m    608\u001b[0m         partition_filter\u001b[39m=\u001b[39;49mpartition_filter,\n\u001b[1;32m    609\u001b[0m         partitioning\u001b[39m=\u001b[39;49mpartitioning,\n\u001b[1;32m    610\u001b[0m         size\u001b[39m=\u001b[39;49msize,\n\u001b[1;32m    611\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    612\u001b[0m         include_paths\u001b[39m=\u001b[39;49minclude_paths,\n\u001b[1;32m    613\u001b[0m         ignore_missing_paths\u001b[39m=\u001b[39;49mignore_missing_paths,\n\u001b[1;32m    614\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m    615\u001b[0m         file_extensions\u001b[39m=\u001b[39;49mfile_extensions,\n\u001b[1;32m    616\u001b[0m         concurrency\u001b[39m=\u001b[39;49mconcurrency,\n\u001b[1;32m    617\u001b[0m         override_num_blocks\u001b[39m=\u001b[39;49moverride_num_blocks,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m reader \u001b[39m=\u001b[39m ImageReader(\n\u001b[1;32m    621\u001b[0m     size\u001b[39m=\u001b[39msize,\n\u001b[1;32m    622\u001b[0m     mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m     open_args\u001b[39m=\u001b[39marrow_open_file_args,\n\u001b[1;32m    626\u001b[0m )\n\u001b[1;32m    627\u001b[0m \u001b[39mreturn\u001b[39;00m read_files(\n\u001b[1;32m    628\u001b[0m     paths,\n\u001b[1;32m    629\u001b[0m     reader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m     ray_remote_args\u001b[39m=\u001b[39mray_remote_args,\n\u001b[1;32m    636\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/read_api.py:917\u001b[0m, in \u001b[0;36mread_images\u001b[0;34m(paths, filesystem, parallelism, meta_provider, ray_remote_args, arrow_open_file_args, partition_filter, partitioning, size, mode, include_paths, ignore_missing_paths, shuffle, file_extensions, concurrency, override_num_blocks)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[39mif\u001b[39;00m meta_provider \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     meta_provider \u001b[39m=\u001b[39m get_image_metadata_provider()\n\u001b[0;32m--> 917\u001b[0m datasource \u001b[39m=\u001b[39m ImageDatasource(\n\u001b[1;32m    918\u001b[0m     paths,\n\u001b[1;32m    919\u001b[0m     size\u001b[39m=\u001b[39;49msize,\n\u001b[1;32m    920\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    921\u001b[0m     include_paths\u001b[39m=\u001b[39;49minclude_paths,\n\u001b[1;32m    922\u001b[0m     filesystem\u001b[39m=\u001b[39;49mfilesystem,\n\u001b[1;32m    923\u001b[0m     meta_provider\u001b[39m=\u001b[39;49mmeta_provider,\n\u001b[1;32m    924\u001b[0m     open_stream_args\u001b[39m=\u001b[39;49marrow_open_file_args,\n\u001b[1;32m    925\u001b[0m     partition_filter\u001b[39m=\u001b[39;49mpartition_filter,\n\u001b[1;32m    926\u001b[0m     partitioning\u001b[39m=\u001b[39;49mpartitioning,\n\u001b[1;32m    927\u001b[0m     ignore_missing_paths\u001b[39m=\u001b[39;49mignore_missing_paths,\n\u001b[1;32m    928\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m    929\u001b[0m     file_extensions\u001b[39m=\u001b[39;49mfile_extensions,\n\u001b[1;32m    930\u001b[0m )\n\u001b[1;32m    931\u001b[0m \u001b[39mreturn\u001b[39;00m read_datasource(\n\u001b[1;32m    932\u001b[0m     datasource,\n\u001b[1;32m    933\u001b[0m     parallelism\u001b[39m=\u001b[39mparallelism,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    936\u001b[0m     override_num_blocks\u001b[39m=\u001b[39moverride_num_blocks,\n\u001b[1;32m    937\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/_internal/datasource/image_datasource.py:44\u001b[0m, in \u001b[0;36mImageDatasource.__init__\u001b[0;34m(self, paths, size, mode, **file_based_datasource_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     38\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     39\u001b[0m     paths: Union[\u001b[39mstr\u001b[39m, List[\u001b[39mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfile_based_datasource_kwargs,\n\u001b[1;32m     43\u001b[0m ):\n\u001b[0;32m---> 44\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(paths, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfile_based_datasource_kwargs)\n\u001b[1;32m     46\u001b[0m     _check_import(\u001b[39mself\u001b[39m, module\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPIL\u001b[39m\u001b[39m\"\u001b[39m, package\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPillow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(size) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/datasource/file_based_datasource.py:115\u001b[0m, in \u001b[0;36mFileBasedDatasource.__init__\u001b[0;34m(self, paths, filesystem, schema, open_stream_args, meta_provider, partition_filter, partitioning, ignore_missing_paths, shuffle, include_paths, file_extensions)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_include_paths \u001b[39m=\u001b[39m include_paths\n\u001b[1;32m    112\u001b[0m paths, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filesystem \u001b[39m=\u001b[39m _resolve_paths_and_filesystem(paths, filesystem)\n\u001b[1;32m    113\u001b[0m paths, file_sizes \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\n\u001b[1;32m    114\u001b[0m     \u001b[39mlist\u001b[39m,\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mzip\u001b[39;49m(\n\u001b[1;32m    116\u001b[0m         \u001b[39m*\u001b[39;49mmeta_provider\u001b[39m.\u001b[39;49mexpand_paths(\n\u001b[1;32m    117\u001b[0m             paths,\n\u001b[1;32m    118\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_filesystem,\n\u001b[1;32m    119\u001b[0m             partitioning,\n\u001b[1;32m    120\u001b[0m             ignore_missing_paths\u001b[39m=\u001b[39;49mignore_missing_paths,\n\u001b[1;32m    121\u001b[0m         )\n\u001b[1;32m    122\u001b[0m     ),\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m ignore_missing_paths \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(paths) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    126\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    127\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNone of the provided paths exist. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore_missing_paths\u001b[39m\u001b[39m'\u001b[39m\u001b[39m field is set to True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/anyscale/data/anyscale_metadata_provider.py:59\u001b[0m, in \u001b[0;36mAnyscaleFileMetadataProvider.expand_paths\u001b[0;34m(self, paths, filesystem, partitioning, ignore_missing_paths)\u001b[0m\n\u001b[1;32m     57\u001b[0m use_sampling \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(is_file(path) \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m paths) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_missing_paths\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(paths) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39myield from\u001b[39;00m _fetch_metadata(paths, filesystem, ignore_missing_paths)\n\u001b[1;32m     60\u001b[0m \u001b[39melif\u001b[39;00m use_sampling:\n\u001b[1;32m     61\u001b[0m     \u001b[39myield from\u001b[39;00m _fetch_metadata_with_sampling_and_tasks_and_threads(\n\u001b[1;32m     62\u001b[0m         paths, filesystem, ignore_missing_paths\n\u001b[1;32m     63\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/anyscale/data/anyscale_metadata_provider.py:75\u001b[0m, in \u001b[0;36m_fetch_metadata\u001b[0;34m(paths, filesystem, ignore_missing_paths)\u001b[0m\n\u001b[1;32m     73\u001b[0m metadata \u001b[39m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m paths:\n\u001b[0;32m---> 75\u001b[0m     metadata\u001b[39m.\u001b[39mextend(_get_file_infos(path, filesystem, ignore_missing_paths))\n\u001b[1;32m     76\u001b[0m \u001b[39mreturn\u001b[39;00m metadata\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/datasource/file_meta_provider.py:424\u001b[0m, in \u001b[0;36m_get_file_infos\u001b[0;34m(path, filesystem, ignore_missing_path)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     ctx \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataContext\u001b[39m.\u001b[39mget_current()\n\u001b[0;32m--> 424\u001b[0m     file_info \u001b[39m=\u001b[39m call_with_retry(\n\u001b[1;32m    425\u001b[0m         \u001b[39mlambda\u001b[39;49;00m: filesystem\u001b[39m.\u001b[39;49mget_file_info(path),\n\u001b[1;32m    426\u001b[0m         description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mget file info\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m         match\u001b[39m=\u001b[39;49mctx\u001b[39m.\u001b[39;49mretried_io_errors,\n\u001b[1;32m    428\u001b[0m     )\n\u001b[1;32m    429\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    430\u001b[0m     _handle_read_os_error(e, path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/_internal/util.py:973\u001b[0m, in \u001b[0;36mcall_with_retry\u001b[0;34m(f, description, match, max_attempts, max_backoff_s)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_attempts):\n\u001b[1;32m    972\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 973\u001b[0m         \u001b[39mreturn\u001b[39;00m f()\n\u001b[1;32m    974\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    975\u001b[0m         is_retryable \u001b[39m=\u001b[39m match \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m    976\u001b[0m             [pattern \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e) \u001b[39mfor\u001b[39;00m pattern \u001b[39min\u001b[39;00m match]\n\u001b[1;32m    977\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/datasource/file_meta_provider.py:425\u001b[0m, in \u001b[0;36m_get_file_infos.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     ctx \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataContext\u001b[39m.\u001b[39mget_current()\n\u001b[1;32m    424\u001b[0m     file_info \u001b[39m=\u001b[39m call_with_retry(\n\u001b[0;32m--> 425\u001b[0m         \u001b[39mlambda\u001b[39;00m: filesystem\u001b[39m.\u001b[39;49mget_file_info(path),\n\u001b[1;32m    426\u001b[0m         description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mget file info\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    427\u001b[0m         match\u001b[39m=\u001b[39mctx\u001b[39m.\u001b[39mretried_io_errors,\n\u001b[1;32m    428\u001b[0m     )\n\u001b[1;32m    429\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    430\u001b[0m     _handle_read_os_error(e, path)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LIMIT = 10 if mode==RunMode.test else 1000\n",
    "img_data = ray.data.read_images(IMG_PATH, include_paths=True, override_num_blocks=20).limit(LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with PaliGemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaliGemmaPredictor:\n",
    "    def __init__(self, prompt=\"caption en\", image_col=\"image\"):\n",
    "        from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "        self.prompt = prompt\n",
    "        self.image_col = image_col\n",
    "        self.model_id = \"google/paligemma-3b-mix-224\"\n",
    "        self.model = PaliGemmaForConditionalGeneration.from_pretrained(self.model_id).eval()\n",
    "        self.processor = AutoProcessor.from_pretrained(self.model_id)\n",
    "\n",
    "    def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, list]:\n",
    "        import torch\n",
    "        # Generate texts from the prompts.\n",
    "        # The output is a list of RequestOutput objects that contain the prompt,\n",
    "        # generated text, and other information.\n",
    "        images = list(batch[self.image_col])\n",
    "        prompts = [self.prompt] * len(images)\n",
    "        model_inputs = self.processor(text=prompts, images=images, return_tensors=\"pt\")\n",
    "        input_len = model_inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            generation = self.model.generate(**model_inputs, max_new_tokens=100, do_sample=False)\n",
    "            mask = torch.tensor([i>=input_len for i in range(generation.shape[1])]).repeat(generation.shape[0],1)\n",
    "            indices = torch.nonzero(mask, as_tuple=True)\n",
    "            decoded = self.processor.batch_decode(generation[indices].reshape(generation.shape[0],-1), skip_special_tokens=True)\n",
    "        \n",
    "        return {\n",
    "            \"captions\": decoded,\n",
    "            \"path\": batch['path'].tolist()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 16:08:02,065\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-22_15-58-40_116452_2325/logs/ray-data\n",
      "2024-09-22 16:08:02,066\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadImage] -> LimitOperator[limit=1000] -> LimitOperator[limit=10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04e629e4c5f47f4a58a2f1c0540f482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadImage 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6a3d3ed2fa417eba424bffef0c71a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1000 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9eab1d1a7a47168e231b093ad17c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=10 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ec338c82a54db482b3cc5035d4730b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "## Test\n",
    "# batch = img_data.take_batch(10)\n",
    "# PaliGemmaPredictor()(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = (\n",
    "    img_data\n",
    "    .map_batches(\n",
    "        PaliGemmaPredictor,\n",
    "        concurrency=4,\n",
    "        num_gpus=1,    \n",
    "        batch_size=100,\n",
    "        accelerator_type=\"A10G\",\n",
    "        fn_constructor_kwargs={\"image_col\": \"image\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 16:10:09,394\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-22_15-58-40_116452_2325/logs/ray-data\n",
      "2024-09-22 16:10:09,395\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadImage] -> LimitOperator[limit=1000] -> ActorPoolMapOperator[MapBatches(PaliGemmaPredictor)] -> TaskPoolMapOperator[Write]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afab25bf5e23479ba9e4402b1b846773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadImage 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b84735f18dd407b84b47e442f347e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1000 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35825878fd21454c9d9096fffea5b816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(PaliGemmaPredictor) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b2b991b4bc4228b8ed3276c2bd8e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Write 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b76574b85b544f68aac0494fd8e9d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 16:15:28,778\tWARNING actor_pool_map_operator.py:265 -- To ensure full parallelization across an actor pool of size 4, the Dataset should consist of at least 4 distinct blocks. Consider increasing the parallelism when creating the Dataset.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ray/default/notebooks/Create-Captions.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://vscode-session-33eser3czbha2i3jm7g2t5am82.i.anyscaleuserdata.com/home/ray/default/notebooks/Create-Captions.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ds\u001b[39m.\u001b[39;49mwrite_parquet(\n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-session-33eser3czbha2i3jm7g2t5am82.i.anyscaleuserdata.com/home/ray/default/notebooks/Create-Captions.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m         path\u001b[39m=\u001b[39;49mCAPTION_PATH,\n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-session-33eser3czbha2i3jm7g2t5am82.i.anyscaleuserdata.com/home/ray/default/notebooks/Create-Captions.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         try_create_dir\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://vscode-session-33eser3czbha2i3jm7g2t5am82.i.anyscaleuserdata.com/home/ray/default/notebooks/Create-Captions.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/dataset.py:2774\u001b[0m, in \u001b[0;36mDataset.write_parquet\u001b[0;34m(self, path, filesystem, try_create_dir, arrow_open_stream_args, filename_provider, arrow_parquet_args_fn, num_rows_per_file, ray_remote_args, concurrency, **arrow_parquet_args)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     arrow_parquet_args_fn \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: {}  \u001b[39m# noqa: E731\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m datasink \u001b[39m=\u001b[39m ParquetDatasink(\n\u001b[1;32m   2764\u001b[0m     path,\n\u001b[1;32m   2765\u001b[0m     arrow_parquet_args_fn\u001b[39m=\u001b[39marrow_parquet_args_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2772\u001b[0m     dataset_uuid\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_uuid,\n\u001b[1;32m   2773\u001b[0m )\n\u001b[0;32m-> 2774\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_datasink(\n\u001b[1;32m   2775\u001b[0m     datasink,\n\u001b[1;32m   2776\u001b[0m     ray_remote_args\u001b[39m=\u001b[39;49mray_remote_args,\n\u001b[1;32m   2777\u001b[0m     concurrency\u001b[39m=\u001b[39;49mconcurrency,\n\u001b[1;32m   2778\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/dataset.py:3608\u001b[0m, in \u001b[0;36mDataset.write_datasink\u001b[0;34m(self, datasink, ray_remote_args, concurrency)\u001b[0m\n\u001b[1;32m   3604\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m   3606\u001b[0m datasink\u001b[39m.\u001b[39mon_write_start()\n\u001b[0;32m-> 3608\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_ds \u001b[39m=\u001b[39m Dataset(plan, logical_plan)\u001b[39m.\u001b[39;49mmaterialize()\n\u001b[1;32m   3609\u001b[0m blocks \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_ds\u001b[39m.\u001b[39m_plan\u001b[39m.\u001b[39mexecute()\u001b[39m.\u001b[39mblock_refs)\n\u001b[1;32m   3610\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m   3611\u001b[0m     \u001b[39misinstance\u001b[39m(block, pd\u001b[39m.\u001b[39mDataFrame) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(block) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m blocks\n\u001b[1;32m   3612\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/dataset.py:4596\u001b[0m, in \u001b[0;36mDataset.materialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4577\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute and materialize this dataset into object store memory.\u001b[39;00m\n\u001b[1;32m   4578\u001b[0m \n\u001b[1;32m   4579\u001b[0m \u001b[39mThis can be used to read all blocks into memory. By default, Dataset\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4593\u001b[0m \u001b[39m    A MaterializedDataset holding the materialized data blocks.\u001b[39;00m\n\u001b[1;32m   4594\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m copy \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m, _deep_copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, _as\u001b[39m=\u001b[39mMaterializedDataset)\n\u001b[0;32m-> 4596\u001b[0m copy\u001b[39m.\u001b[39;49m_plan\u001b[39m.\u001b[39;49mexecute()\n\u001b[1;32m   4598\u001b[0m bundle \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39m_plan\u001b[39m.\u001b[39m_snapshot_bundle\n\u001b[1;32m   4599\u001b[0m blocks_with_metadata \u001b[39m=\u001b[39m bundle\u001b[39m.\u001b[39mblocks\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/exceptions.py:49\u001b[0m, in \u001b[0;36momit_traceback_stdout.<locals>.handle_trace\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandle_trace\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     48\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     50\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     51\u001b[0m         \u001b[39m# Only log the full internal stack trace to stdout when configured\u001b[39;00m\n\u001b[1;32m     52\u001b[0m         \u001b[39m# via DataContext, or when the Ray Debugger is enabled.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m         \u001b[39m# The full stack trace will always be emitted to the Ray Data log file.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         log_to_stdout \u001b[39m=\u001b[39m DataContext\u001b[39m.\u001b[39mget_current()\u001b[39m.\u001b[39mlog_internal_stack_trace_to_stdout\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/_internal/plan.py:502\u001b[0m, in \u001b[0;36mExecutionPlan.execute\u001b[0;34m(self, preserve_order)\u001b[0m\n\u001b[1;32m    497\u001b[0m metrics_tag \u001b[39m=\u001b[39m create_dataset_tag(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_uuid)\n\u001b[1;32m    498\u001b[0m executor \u001b[39m=\u001b[39m StreamingExecutor(\n\u001b[1;32m    499\u001b[0m     copy\u001b[39m.\u001b[39mdeepcopy(context\u001b[39m.\u001b[39mexecution_options),\n\u001b[1;32m    500\u001b[0m     metrics_tag,\n\u001b[1;32m    501\u001b[0m )\n\u001b[0;32m--> 502\u001b[0m blocks \u001b[39m=\u001b[39m execute_to_legacy_block_list(\n\u001b[1;32m    503\u001b[0m     executor,\n\u001b[1;32m    504\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    505\u001b[0m     dataset_uuid\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_uuid,\n\u001b[1;32m    506\u001b[0m     preserve_order\u001b[39m=\u001b[39;49mpreserve_order,\n\u001b[1;32m    507\u001b[0m )\n\u001b[1;32m    508\u001b[0m bundle \u001b[39m=\u001b[39m RefBundle(\n\u001b[1;32m    509\u001b[0m     \u001b[39mtuple\u001b[39m(blocks\u001b[39m.\u001b[39miter_blocks_with_metadata()),\n\u001b[1;32m    510\u001b[0m     owns_blocks\u001b[39m=\u001b[39mblocks\u001b[39m.\u001b[39m_owned_by_consumer,\n\u001b[1;32m    511\u001b[0m )\n\u001b[1;32m    512\u001b[0m stats \u001b[39m=\u001b[39m executor\u001b[39m.\u001b[39mget_stats()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/legacy_compat.py:123\u001b[0m, in \u001b[0;36mexecute_to_legacy_block_list\u001b[0;34m(executor, plan, dataset_uuid, preserve_order)\u001b[0m\n\u001b[1;32m    117\u001b[0m dag, stats \u001b[39m=\u001b[39m _get_execution_dag(\n\u001b[1;32m    118\u001b[0m     executor,\n\u001b[1;32m    119\u001b[0m     plan,\n\u001b[1;32m    120\u001b[0m     preserve_order,\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    122\u001b[0m bundles \u001b[39m=\u001b[39m executor\u001b[39m.\u001b[39mexecute(dag, initial_stats\u001b[39m=\u001b[39mstats)\n\u001b[0;32m--> 123\u001b[0m block_list \u001b[39m=\u001b[39m _bundles_to_block_list(bundles)\n\u001b[1;32m    124\u001b[0m \u001b[39m# Set the stats UUID after execution finishes.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m _set_stats_uuid_recursive(executor\u001b[39m.\u001b[39mget_stats(), dataset_uuid)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/legacy_compat.py:169\u001b[0m, in \u001b[0;36m_bundles_to_block_list\u001b[0;34m(bundles)\u001b[0m\n\u001b[1;32m    167\u001b[0m blocks, metadata \u001b[39m=\u001b[39m [], []\n\u001b[1;32m    168\u001b[0m owns_blocks \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m \u001b[39mfor\u001b[39;00m ref_bundle \u001b[39min\u001b[39;00m bundles:\n\u001b[1;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ref_bundle\u001b[39m.\u001b[39mowns_blocks:\n\u001b[1;32m    171\u001b[0m         owns_blocks \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/interfaces/executor.py:37\u001b[0m, in \u001b[0;36mOutputIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RefBundle:\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_next()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/streaming_executor.py:145\u001b[0m, in \u001b[0;36mStreamingExecutor.execute.<locals>.StreamIterator.get_next\u001b[0;34m(self, output_split_idx)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_next\u001b[39m(\u001b[39mself\u001b[39m, output_split_idx: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RefBundle:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m         item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_outer\u001b[39m.\u001b[39;49m_output_node\u001b[39m.\u001b[39;49mget_output_blocking(\n\u001b[1;32m    146\u001b[0m             output_split_idx\n\u001b[1;32m    147\u001b[0m         )\n\u001b[1;32m    148\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outer\u001b[39m.\u001b[39m_global_info:\n\u001b[1;32m    149\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outer\u001b[39m.\u001b[39m_global_info\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m, dag\u001b[39m.\u001b[39mnum_outputs_total())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ray/data/_internal/execution/streaming_executor_state.py:290\u001b[0m, in \u001b[0;36mOpState.get_output_blocking\u001b[0;34m(self, output_split_idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m ref \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m ref\n\u001b[0;32m--> 290\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds.write_parquet(\n",
    "        path=CAPTION_PATH,\n",
    "        try_create_dir=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8515aceeb29349be86b7779cbf1ccd77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parquet Files Sample 0:   0%|          | 0/2 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 07:00:58,669\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-09-21_20-17-17_494561_3381/logs/ray-data\n",
      "2024-09-22 07:00:58,670\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8eee3396d874956974205ce68a85578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadParquet->SplitBlocks(8) 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f074edba0e64ac89bc0d32de8f81107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d84912bddfa4299aedd6085a3528952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'captions': 'a blue plaid scarf with a white tag on it.', 'path': 'anyscale-customer-dataplane-data-production-us-east-2/artifact_storage/org_6687q89lgh27q3z41zesm2fsq6/cld_j25ipm5kli358v41pn9c96gjg3/BurberryData:john_:kpbdm/images/0003C5D9-CD9D-4853-8A4C-86B331349517.png'}\n"
     ]
    }
   ],
   "source": [
    "ray.data.read_parquet(CAPTION_PATH).show(limit=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
